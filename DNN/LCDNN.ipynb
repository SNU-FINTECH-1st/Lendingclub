{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16fb26a-b98f-44be-aae9-b6b1d1cb9dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import pandas\n",
    "import numpy\n",
    "import torch.nn.functional\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "## Prepare Data set\n",
    "temp_data=pandas.read_csv('D:/Data study/data analysis project/lending club/current_out_all_clean_data.csv')\n",
    "\n",
    "temp_data['purpose']\n",
    "\n",
    "y_temp=temp_data['total_rec_prncp']/temp_data['funded_amnt']\n",
    "\n",
    "\n",
    "def clean_data(x) :\n",
    "    x.replace([numpy.inf],0,inplace=True)\n",
    "    x.replace([numpy.NAN],0,inplace=True)\n",
    "\n",
    "clean_data(y_temp)\n",
    "temp_data['revol_util']=temp_data['revol_util'].str.replace('%', '').astype(float)\n",
    "\n",
    "temp_data.drop('id',axis=1,inplace=True)\n",
    "select_feature='''\n",
    "annual_inc\n",
    "inq_last_6mths\n",
    "sub_grade\n",
    "installment\n",
    "tot_cur_bal\n",
    "avg_cur_bal\n",
    "mo_sin_old_rev_tl_op\n",
    "mo_sin_rcnt_rev_tl_op\n",
    "mo_sin_rcnt_tl\n",
    "mort_acc\n",
    "num_il_tl\n",
    "num_tl_120dpd_2m\n",
    "num_tl_op_past_12m\n",
    "revol_bal\n",
    "total_bc_limit\n",
    "dti\n",
    "out_prncp\n",
    "out_prncp_inv\n",
    "total_pymnt\n",
    "total_pymnt_inv\n",
    "total_rec_prncp\n",
    "total_rec_int\n",
    "total_rec_late_fee\n",
    "tot_hi_cred_lim\n",
    "loan_amnt\n",
    "term\n",
    "emp_length\n",
    "home_ownership\n",
    "purpose\n",
    "delinq_2yrs\n",
    "revol_util\n",
    "application_type\n",
    "open_act_il\n",
    "open_rv_24m\n",
    "max_bal_bc\n",
    "all_util\n",
    "acc_open_past_24mths\n",
    "num_op_rev_tl\n",
    "num_rev_accts\n",
    "num_tl_90g_dpd_24m\n",
    "pct_tl_nvr_dlq\n",
    "last_fico_range_high\n",
    "last_fico_range_low\n",
    "emp_length\n",
    "verification_status\n",
    "open_acc\n",
    "pub_rec_bankruptcies\n",
    "pub_rec\n",
    "tax_liens\n",
    "chargeoff_within_12_mths\n",
    "'''\n",
    "select_feature=select_feature.strip().split('\\n')\n",
    "x_temp=temp_data[select_feature]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def splitset(x,y) :\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.25, random_state=42)\n",
    "    return x_train.reset_index(drop=True),\\\n",
    "        y_train.reset_index(drop=True),\\\n",
    "        x_valid.reset_index(drop=True),\\\n",
    "        y_valid.reset_index(drop=True),\\\n",
    "        x_test.reset_index(drop=True),\\\n",
    "        y_test.reset_index(drop=True)\n",
    "\n",
    "bx_train,y_train,bx_valid, y_valid,bx_test,y_test=splitset(x_temp,y_temp)\n",
    "\n",
    "## scaling, encoding\n",
    "def onehot_train_valid(x_train,x_valid) :\n",
    "    one=OneHotEncoder()\n",
    "    temp_final=pandas.DataFrame()\n",
    "    temp_valid_final=pandas.DataFrame()\n",
    "    temp_data=x_train.select_dtypes(include='object')\n",
    "    temp_data2=x_valid.select_dtypes(include='object')\n",
    "    for i in range(0,len(temp_data.columns)):\n",
    "        one.fit(temp_data.iloc[:,i].values.reshape(-1,1))\n",
    "        temp_x=one.transform(temp_data.iloc[:,i].values.reshape(-1,1)).toarray().astype(int)\n",
    "        temp_x=pandas.DataFrame(temp_x,\n",
    "                            columns=[str(one.categories_[0][i]) for i in\n",
    "                                     range(len(one.categories_[0]))\n",
    "                            ]\n",
    "                            )\n",
    "        temp_x_valid = one.transform(temp_data2.iloc[:, i].values.reshape(-1, 1)).toarray().astype(int)\n",
    "        temp_x_valid = pandas.DataFrame(temp_x_valid,\n",
    "                              columns=[str(one.categories_[0][i]) for i in\n",
    "                                       range(len(one.categories_[0]))\n",
    "                                       ]\n",
    "                              )\n",
    "\n",
    "        temp_final=pandas.concat([temp_x,temp_final],axis=1)\n",
    "        temp_valid_final=pandas.concat([temp_x_valid,temp_valid_final],axis=1)\n",
    "    return temp_final.reset_index(drop=True), temp_valid_final.reset_index(drop=True)\n",
    "\n",
    "def stsc_train_valid(x_train,x_valid) :\n",
    "    stdsc=StandardScaler()\n",
    "    temp_x=x_train.select_dtypes(exclude='object')\n",
    "    temp_valid=x_valid.select_dtypes(exclude='object')\n",
    "    name=temp_x.columns\n",
    "    stdsc.fit(numpy.array(temp_x).reshape(-1,len(name)))\n",
    "    temp_x = stdsc.transform(numpy.array(temp_x).reshape(-1, len(name)))\n",
    "    temp_x=pandas.DataFrame(temp_x)\n",
    "    temp_x.columns=name\n",
    "    temp_x_valid=stdsc.transform(numpy.array(temp_valid).reshape(-1,len(name)))\n",
    "    temp_x_valid=pandas.DataFrame(temp_x_valid)\n",
    "    temp_x_valid.columns=name\n",
    "\n",
    "    return temp_x.reset_index(drop=True), temp_x_valid.reset_index(drop=True)\n",
    "\n",
    "one_train,one_valid=onehot_train_valid(x_train=bx_train,x_valid=bx_valid)\n",
    "stsc_train,stsc_valid=stsc_train_valid(bx_train,bx_valid)\n",
    "\n",
    "x_train=pandas.concat([stsc_train,one_train],axis=1)\n",
    "x_valid=pandas.concat([stsc_valid,one_valid],axis=1)\n",
    "\n",
    "\n",
    "# tensor로 전달\n",
    "x_train_tensor = torch.tensor(x_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "\n",
    "x_valid_tensor = torch.tensor(x_valid.values, dtype=torch.float32)\n",
    "y_valid_tensor = torch.tensor(y_valid.values, dtype=torch.float32)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train_tensor, y_train_tensor)\n",
    "valid_dataset = torch.utils.data.TensorDataset(x_valid_tensor, y_valid_tensor)\n",
    "\n",
    "\n",
    "# 데이터를 데이터 로더에 전달\n",
    "train_loader=torch.utils.data.DataLoader(train_dataset,batch_size=100)\n",
    "valid_loader=torch.utils.data.DataLoader(valid_dataset,batch_size=100)\n",
    "\n",
    "\n",
    "\n",
    "## 신경망 정의\n",
    "n_feature=len(x_train.columns)\n",
    "class LCDNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LCDNN,self).__init__()\n",
    "        self.fc1=torch.nn.Linear(in_features= n_feature,out_features=32,bias=True) # 히든 레이어\n",
    "        self.drop=torch.nn.Dropout(0.25) # p만큼의 비율로 텐서의 값이 0이 되고 0이 아닌 값은 1/(1-p)만큼 곱해서 커짐,\n",
    "        self.fc2=torch.nn.Linear(in_features= 32 ,out_features=16,bias=True)\n",
    "        self.fc3=torch.nn.Linear(in_features= 16 ,out_features=1,bias=True)\n",
    "\n",
    "    def forward(self,input_data):\n",
    "        out=input_data.view(-1, n_feature)\n",
    "        out=torch.nn.functional.relu(self.fc1(out))\n",
    "        out=self.drop(out)\n",
    "        out=torch.nn.functional.relu(self.fc2(out))\n",
    "        out=self.fc3(out)\n",
    "        return out\n",
    "\n",
    "# backward는 잘 정의하지 않는다\n",
    "\n",
    "# gpu 설정\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## 파라미터 정의\n",
    "learning_rate=0.001\n",
    "model=LCDNN()\n",
    "model.to(device)\n",
    "\n",
    "criterion=torch.nn.MSELoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate) # Adamgrid!!\n",
    "\n",
    "\n",
    "\n",
    "## optimize\n",
    "num_epochs=5 # early stopping 한번 찾아볼게요\n",
    "count=0\n",
    "loss_list=[]\n",
    "iteration_list=[]\n",
    "\n",
    "predictions_list=[]\n",
    "labels_list=[]\n",
    "\n",
    "\n",
    "#\n",
    "# # train\n",
    "# for epoch in range(num_epochs):\n",
    "#     for feature, labels in train_loader :\n",
    "#         feature, labels = feature.to(device), labels.to(device)\n",
    "#         train=Variable(feature.view(feature.size(0) ,-1))\n",
    "#         labels=Variable(labels)\n",
    "#         outputs=model(train)\n",
    "#         loss=criterion(outputs,labels)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         count +=1\n",
    "#\n",
    "#         if count % 500 == 0:\n",
    "#             model.eval()  # Set the model to evaluation mode\n",
    "#             total_loss = 0\n",
    "#             total_mse = 0.0\n",
    "#             with torch.no_grad():\n",
    "#                 for inputs, targets in valid_loader:\n",
    "#                     inputs, targets = inputs.to(device), targets.to(device)\n",
    "#                     test = Variable(inputs.view(inputs.size(0), -1))  # Flatten the input\n",
    "#                     outputs = model(test)\n",
    "#                     loss = criterion(outputs, targets)\n",
    "#                     total_loss += loss.item()\n",
    "#                     mse = torch.nn.functional.mse_loss(outputs, targets)\n",
    "#                     total_mse += mse.item()\n",
    "#\n",
    "#             average_loss = total_loss / len(valid_loader)\n",
    "#             average_mse=total_mse/len(valid_loader)\n",
    "#             print(f\"Iteration: {count}, Validation Loss: {average_loss},Average_mse: {average_mse}\")\n",
    "\n",
    "\n",
    "\n",
    "count = 0  # Initialize count\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for feature, labels in train_loader:\n",
    "        feature, labels = feature.to(device), labels.to(device)\n",
    "        train = feature.view(feature.size(0), -1)  # Flatten the input\n",
    "        outputs = model(train)\n",
    "\n",
    "        # Ensure outputs and labels have the same size\n",
    "        if outputs.size(1) == 1:\n",
    "            outputs = outputs.squeeze(1)  # [batch_size, 1] -> [batch_size]\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        count += 1  # Increment count after each training step\n",
    "\n",
    "        if count % 500 == 0:\n",
    "            model.eval()  # Set the model to evaluation mode\n",
    "            total_loss = 0\n",
    "            total_mse = 0.0\n",
    "            total_mape = 0.0\n",
    "            total_r2 = 0.0\n",
    "            num_samples_mape = 0  # To count valid MAPE samples\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in valid_loader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    test = inputs.view(inputs.size(0), -1)  # Flatten the input\n",
    "                    outputs = model(test)\n",
    "\n",
    "                    # Ensure outputs and targets have the same size\n",
    "                    if outputs.size(1) == 1:\n",
    "                        outputs = outputs.squeeze(1)  # [batch_size, 1] -> [batch_size]\n",
    "\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    total_loss += loss.item()\n",
    "\n",
    "                    # MSE\n",
    "                    mse = torch.nn.functional.mse_loss(outputs, targets)\n",
    "                    total_mse += mse.item()\n",
    "\n",
    "                    # MAPE\n",
    "                    epsilon = 1e-8\n",
    "                    non_zero_targets = torch.abs(targets) > epsilon\n",
    "                    if torch.sum(non_zero_targets) > 0:\n",
    "                        mape = torch.mean(torch.abs((targets[non_zero_targets] - outputs[non_zero_targets]) /\n",
    "                                                     (targets[non_zero_targets] + epsilon))) * 100\n",
    "                        total_mape += mape.item()\n",
    "                        num_samples_mape += 1\n",
    "\n",
    "                    # R² Score\n",
    "                    y_mean = torch.mean(targets)\n",
    "                    ss_tot = torch.sum((targets - y_mean) ** 2)\n",
    "                    ss_res = torch.sum((targets - outputs) ** 2)\n",
    "                    r2 = 1 - (ss_res / ss_tot) if ss_tot.item() != 0 else float('nan')  # Handle case where ss_tot is zero\n",
    "                    total_r2 += r2\n",
    "\n",
    "            average_loss = total_loss / len(valid_loader)\n",
    "            average_mse = total_mse / len(valid_loader)\n",
    "            average_mape = total_mape / num_samples_mape if num_samples_mape > 0 else float('nan')\n",
    "            average_r2 = total_r2 / len(valid_loader) if len(valid_loader) > 0 else float('nan')\n",
    "\n",
    "            print(f\"Iteration: {count}, Validation Loss: {average_loss:.4f}, Average MSE: {average_mse:.4f}, \"\n",
    "                  f\"Average MAPE: {average_mape:.4f}%, Average R²: {average_r2:.4f}\")\n",
    "model.parameters()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
